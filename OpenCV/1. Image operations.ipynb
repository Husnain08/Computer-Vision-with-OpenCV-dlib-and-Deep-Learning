{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('opencv-logo.png' , 1)\n",
    "# passing a value of 0 to the imread function reads the image as a black & white image while a value of 1 reads an image as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISPLAYING AN IMAGE\n",
    "cv2.namedWindow(\"Image\" , cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the image back to file\n",
    "cv2.imwrite(\"output.jpg\" , img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 600, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing and understanding pixel data\n",
    "img # display's the pixels of an image\n",
    "len(img) # number of pixels\n",
    "len(img[0][0]) # number of channels\n",
    "img.shape # image of the picture - Height * Width * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n",
      "1330200\n"
     ]
    }
   ],
   "source": [
    "#slice an imgae\n",
    "print(img[10, 5]) # image pixel at 10th row and 5th column\n",
    "print (img.size) # total number of pixels in an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Types and Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate a grey image by a numpy array\n",
    "black_img = np.zeros([150,200,1] , 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Black\" , black_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate a white color image by a numpy array\n",
    "color_img = np.ones([150,200,3] , 'uint8')\n",
    "color_img *= (2**8-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Color\" , color_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate a blue color image by a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_copy = color_img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR format.\n",
    "color_copy[:,:] = (255,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Blue image\" , color_copy)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Type and color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"butterfly.jpg\" , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\" , img)\n",
    "cv2.moveWindow(\"Image\" , 0 , 0) # place the image to the top left hand side of the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting out the image channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b , g , r = cv2.split(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "height , width , channels = img.shape\n",
    "rgb_split = np.empty([height , width*3 , 3] , 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the blue channel of the image\n",
    "rgb_split[: , 0:width] = cv2.merge([b,b,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the green channel of the image\n",
    "rgb_split[: , width:width*2] = cv2.merge([g,g,g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the green channel of the image\n",
    "rgb_split[: , width*2: width*3] = cv2.merge([r,r,r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "cv2.imshow(\"Channels\" , rgb_split)\n",
    "cv2.moveWindow(\"Channels \", 0, height)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hue saturation value (HSV Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(img , cv2.COLOR_BGR2HSV) # convert image from bgr to hsv\n",
    "h , s , v = cv2.split(hsv) # split the channels\n",
    "hsv_split = np.concatenate((h , s , v), axis = 1)# concatenate the individual channels\n",
    "cv2.imshow(\"HSV_Split images \" , hsv_split)\n",
    "cv2.imshow(\"Channels\" , rgb_split)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel manipulation and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting image from color to gray-scale\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_RGB2GRAY)\n",
    "cv2.imwrite(\"gray.jpg\" , gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an additional channel ( alpha channel) in a color image as a transparent channels that will make an image transparent\n",
    "#according to the added channel. If this is a green channel, then the green color in the image will become transparent and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img[:,:,0] # blue channel of the image \n",
    "g = img[:,:,1] # green channel of the image \n",
    "r = img[:,:,2] #  red channel of the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgba = cv2.merge((b,g,r,g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"rgba.png\" , rgba) #jpeg images does not support transparency, that is why we are using jpg files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blur, Dialation and Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"thresh.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\" , img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gaussian blur\n",
    "blur = cv2.GaussianBlur(img , (5,55) , 0) # 5 and 55 are the values for the gaussian filter to blur the image on the x and y axis respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"blur\" , blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dialation effect works to turn black pixels into white pixels while\n",
    "# An erosion filter looks to turn white pixels into black pixels\n",
    "# The image is convolved with a kernel which does either erosion or dialation depending on its elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dialate filter\n",
    "dilate = cv2.dilate(img , kernel , iterations = 1) \n",
    "# Erosion filter\n",
    "erode = cv2.erode(img , kernel , iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both of these filters can sometimes be used to remove all the noise from the image \n",
    "cv2.imshow(\"Dilate\" , dilate)\n",
    "cv2.imshow(\"Erosion\" , erode)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale and rotate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"players.jpg\" , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the image\n",
    "img_half = cv2.resize(img,None,fx=0.5,fy=0.5)\n",
    "img_strech = cv2.resize(img , (600,600))\n",
    "img_strech_near = cv2.resize(img, (600,600) , interpolation = cv2.INTER_NEAREST) # USING INTERPLOATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Halved\" , img_half)\n",
    "cv2.imshow(\"Streched\" , img_strech)\n",
    "cv2.imshow(\"Streched with Interpolation\" , img_strech_near)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "M = cv2.getRotationMatrix2D((0,0) , -30 , 1)  # transformation matrix which rotates the image from the top left cornet by -30 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = cv2.warpAffine(img , M , (img.shape[1] , img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Rotated\" , rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using video inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret , frame = video_capture.read() # Read a new frame from the video capture\n",
    "    frame = cv2.resize(frame , (0,0) , fx = 0.5 , fy = 0.5)\n",
    "    cv2.imshow(\"Frame \" , frame)\n",
    "    ch = cv2.waitKey(1) \n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Custom Interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "# Frame Re-sizing\n",
    "color = (0,255,0) # color of our circle\n",
    "line_width = 3 # A value of -1 indicates that the circle will be filled\n",
    "radius = 100\n",
    "initial_point = (0,0)\n",
    "\n",
    "# Writing a function for capturing mouse click\n",
    "def click(event , x , y , flags , param):\n",
    "    global initial_point , pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Pressed\" , x,y) # priniting the x and y values for debugging purposes\n",
    "        point = (x,y)\n",
    "    \n",
    "# register the click with the OpenCV Handler\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\" , click)\n",
    "\n",
    "while(True):\n",
    "    ret , frame = capture.read() # Read a new frame from the video capture\n",
    "    frame = cv2.resize(frame , (0,0) , fx = 0.5 , fy = 0.5)\n",
    "    cv2.circle(frame , initial_point , radius, color,line_width) # draw the circle\n",
    "    cv2.imshow(\"Frame \" , frame)\n",
    "    ch = cv2.waitKey(1) \n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Drawing App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, define a canvas\n",
    "canvas = np.ones([500,500,3] , \"uint8\") ** 255 # Initialize a canvas with a white background\n",
    "radius = 3 # radius\n",
    "pressed = False # if the button is pressed\n",
    "color = (0,255,0) # default color (green)\n",
    "def click(event , x, y,flags, param):\n",
    "    global canvas , pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN: # if mouse is clicked \n",
    "        pressed = True \n",
    "        cv2.circle(canvas,(x,y) , radius , color , -1) # draw the circle\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and pressed == True: # if mouse is moved\n",
    "        cv2.circle(canvas , (x,y) , radius , color , -1) # keep drawing the circle\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        pressed = False\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"canvas\" , click)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"canvas\" , canvas)\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'): # press q to quit the program\n",
    "        break\n",
    "    elif ch & 0xFF == ord('b'):  # if we press button 'b'\n",
    "        color = (255,0,0) # sets the color to blue\n",
    "    elif ch & 0xFF == ord('g'): # if we press button 'red'\n",
    "        color = (0,255,0) # sets the color to red\n",
    "cv2.destroyAllWindows()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
