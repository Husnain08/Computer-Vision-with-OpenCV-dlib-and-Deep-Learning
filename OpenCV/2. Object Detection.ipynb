{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"detect_blob.png\" , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height , width = img.shape[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original image\" , img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "binary_variable = np.zeros([height,  width , 1] , \"uint8\")\n",
    "threshold = 85\n",
    "for row in range(0 , height):\n",
    "    for col in range(0,width):\n",
    "        if img[row][col] > threshold:\n",
    "            binary_variable[row][col] = 255\n",
    "cv2.imshow(\"Binary thresholding\",binary_variable)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the built-in cv2 binary thresholding ( faster than the above method)\n",
    "ret , thresh = cv2.threshold(img,threshold , 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"CV2 thresholding\",thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"sudoku.png\" , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original\" , img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the built-in thresholding function of cv2\n",
    "ret , threshold = cv2.threshold(img , 70 , 255 , cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Basic threshold \" , threshold)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_adapt = cv2.adaptiveThreshold(img , 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C , cv2.THRESH_BINARY , 115,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Adaptive Threshold \", thresh_adapt)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skin Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"faces.jpeg\" , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(img , cv2.COLOR_BGR2HSV)\n",
    "h = hsv[:,:,0] # hue channel values\n",
    "s = hsv[:,:,1] # saturation channel values\n",
    "v = hsv[:,:,2] # value channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the channels\n",
    "hsv_split = np.concatenate((h,s,v), axis = 1)\n",
    "cv2.imshow(\"Channels\" , hsv_split)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on the saturation channel\n",
    "ret , min_saturation = cv2.threshold(s,40,255,cv2.THRESH_BINARY) # any pixel value greater than 15 is turned to white\n",
    "cv2.imshow(\"Hue saturation\" , min_saturation)\n",
    "\n",
    "# filter on the hue channel\n",
    "ret , max_hue = cv2.threshold(h,15,255,cv2.THRESH_BINARY_INV) # Maximum value that we want would be 15 -\n",
    "#it makes all pixel values from 0 to 15 to white  \n",
    "cv2.imshow(\"Hue Filter\" , max_hue)\n",
    "# combining the two filters together\n",
    "final = cv2.bitwise_and(min_saturation , max_hue)\n",
    "cv2.imshow(\"Final\" , final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contour object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"detect_blob.png\" , 1)\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_RGB2GRAY)\n",
    "threshold = cv2.adaptiveThreshold(gray , 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C , cv2.THRESH_BINARY , 115,1)\n",
    "cv2.imshow(\"Binary threshold\" , thresh)\n",
    "contours , hierarchy = cv2.findContours(thresh , cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
    "img2 = img.copy()\n",
    "index = -1 # index of the contours we want to draw\n",
    "thickness = 4\n",
    "color = (255,0,255) # pink color\n",
    "cv2.drawContours(img2 , contours , index,color,thickness)\n",
    "cv2.imshow(\"Contours\" , img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area , perimeter , center, and curvature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area: 13085.5 , perimeter: 756.8700572252274\n",
      "Area: 10004.5 , perimeter: 403.0710676908493\n",
      "Area: 283.5 , perimeter: 63.69848430156708\n",
      "Area: 0.0 , perimeter: 0.0\n",
      "Area: 7776.0 , perimeter: 329.22034442424774\n",
      "Area: 5.5 , perimeter: 9.071067690849304\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 26.0 , perimeter: 21.313708305358887\n",
      "Area: 0.0 , perimeter: 2.0\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 2.0 , perimeter: 5.656854152679443\n",
      "Area: 4160.0 , perimeter: 258.0\n",
      "Area: 1672.0 , perimeter: 160.48528122901917\n",
      "Area: 14500.5 , perimeter: 1226.0113161802292\n",
      "Area: 6019.0 , perimeter: 456.3675308227539\n",
      "Area: 7629.0 , perimeter: 484.8284270763397\n",
      "Area: 5014.5 , perimeter: 443.78174436092377\n",
      "Area: 8811.0 , perimeter: 449.7644991874695\n",
      "Area: 551.5 , perimeter: 93.41421353816986\n",
      "Area: 2704.5 , perimeter: 194.75230717658997\n",
      "Area: 1642.5 , perimeter: 151.29646348953247\n",
      "Area: 767.0 , perimeter: 105.74011433124542\n",
      "Area: 3497.5 , perimeter: 251.0710676908493\n",
      "Area: 8546.0 , perimeter: 345.70562517642975\n",
      "Area: 8865.0 , perimeter: 378.8284270763397\n",
      "Area: 745.0 , perimeter: 102.9116872549057\n",
      "Area: 1634.0 , perimeter: 152.36753070354462\n",
      "Area: 1.0 , perimeter: 4114.82842707634\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"detect_blob.png\" , 1)\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "threshold = cv2.adaptiveThreshold(gray , 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C , cv2.THRESH_BINARY , 115,-1)\n",
    "\n",
    "cv2.imshow(\"Binary threshold\" , threshold)\n",
    "\n",
    "contours , hierarchy = cv2.findContours(threshold , cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "contours = np.asarray(contours)\n",
    "\n",
    "img2 = img.copy()\n",
    "index = -1 # index of the contours we want to draw\n",
    "thickness = 4\n",
    "color = (255,0,255) # pink color\n",
    "\n",
    "objects = np.zeros([img.shape[0] , img.shape[1] , 3], \"uint8\")\n",
    "for c in contours:\n",
    "    cv2.drawContours(objects , c , -1 , color,-1)\n",
    "    area = cv2.contourArea(c)\n",
    "    perimeter = cv2.arcLength(c , True)\n",
    "    M= cv2.moments(c) # moment of the contour\n",
    "    if M[\"m00\"] != 0:\n",
    "        centroid_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        centroid_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        centroid_x, centroid_y = 0, 0\n",
    "    cv2.circle(objects , (centroid_x,centroid_y) , 4 , (0,0,255), -1)\n",
    "    print (\"Area: {} , perimeter: {}\".format(area , perimeter))\n",
    "cv2.imshow(\"Contours \" , objects)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable          Type       Data/Info\n",
      "--------------------------------------\n",
      "M                 dict       n=24\n",
      "area              float      1.0\n",
      "binary_variable   ndarray    760x541x1: 411160 elems, type `uint8`, 411160 bytes (401.5234375 kb)\n",
      "blur              ndarray    300x400: 120000 elems, type `uint8`, 120000 bytes (117.1875 kb)\n",
      "c                 ndarray    8x1x2: 16 elems, type `int32`, 64 bytes\n",
      "centroid_x        int        270\n",
      "centroid_y        int        0\n",
      "col               tuple      n=3\n",
      "color             tuple      n=3\n",
      "contours          ndarray    37: 37 elems, type `object`, 296 bytes\n",
      "cv2               module     <module 'cv2.cv2' from 'C<...>\\cv2.cp37-win_amd64.pyd'>\n",
      "edges             ndarray    700x1054: 737800 elems, type `uint8`, 737800 bytes (720.5078125 kb)\n",
      "filtered          list       n=4\n",
      "final             ndarray    3080x3080: 9486400 elems, type `uint8`, 9486400 bytes (9.04693603515625 Mb)\n",
      "gray              ndarray    760x541: 411160 elems, type `uint8`, 411160 bytes (401.5234375 kb)\n",
      "h                 ndarray    3080x3080: 9486400 elems, type `uint8`, 9486400 bytes (9.04693603515625 Mb)\n",
      "height            int        760\n",
      "hierarchy         ndarray    1x37x4: 148 elems, type `int32`, 592 bytes\n",
      "hsv               ndarray    700x1054x3: 2213400 elems, type `uint8`, 2213400 bytes (2.1108627319335938 Mb)\n",
      "hsv_split         ndarray    3080x9240: 28459200 elems, type `uint8`, 28459200 bytes (27.14080810546875 Mb)\n",
      "img               ndarray    760x541x3: 1233480 elems, type `uint8`, 1233480 bytes (1.1763381958007812 Mb)\n",
      "img2              ndarray    760x541x3: 1233480 elems, type `uint8`, 1233480 bytes (1.1763381958007812 Mb)\n",
      "index             int        -1\n",
      "max_hue           ndarray    3080x3080: 9486400 elems, type `uint8`, 9486400 bytes (9.04693603515625 Mb)\n",
      "min_saturation    ndarray    3080x3080: 9486400 elems, type `uint8`, 9486400 bytes (9.04693603515625 Mb)\n",
      "np                module     <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "objects           ndarray    760x541x3: 1233480 elems, type `uint8`, 1233480 bytes (1.1763381958007812 Mb)\n",
      "perimeter         float      4114.82842707634\n",
      "random            module     <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "res               float      25.0\n",
      "ret               float      15.0\n",
      "row               int        759\n",
      "s                 ndarray    3080x3080: 9486400 elems, type `uint8`, 9486400 bytes (9.04693603515625 Mb)\n",
      "thersh            ndarray    700x1054: 737800 elems, type `uint8`, 737800 bytes (720.5078125 kb)\n",
      "thickness         int        4\n",
      "thresh            ndarray    300x400: 120000 elems, type `uint8`, 120000 bytes (117.1875 kb)\n",
      "thresh_adapt      ndarray    563x558: 314154 elems, type `uint8`, 314154 bytes (306.791015625 kb)\n",
      "threshold         ndarray    760x541: 411160 elems, type `uint8`, 411160 bytes (401.5234375 kb)\n",
      "v                 ndarray    3080x3080: 9486400 elems, type `uint8`, 9486400 bytes (9.04693603515625 Mb)\n",
      "width             int        541\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canny Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread(\"tomatoes.jpg\" , 1)\n",
    "# let's try a threshold\n",
    "hsv = cv2.cvtColor(img2 , cv2.COLOR_BGR2HSV)\n",
    "res , thresh = cv2.threshold(hsv[:,:,0] , 25,255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "# Simples thresholding is combining multiple objects and presenting them as a single object\n",
    "\n",
    "\n",
    "# Now we'll use a canny edge detector\n",
    "edges = cv2.Canny(img2 , 100,70)\n",
    "cv2.imshow(\"canny\" , edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning object ID and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2054\n",
      "4\n",
      "4926.0 298.2253956794739\n",
      "29882.0 795.3868639469147\n",
      "1038.0 645.0681030750275\n",
      "17250.0 585.0782079696655\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "img = cv2.imread(\"fuzzy.png\" , 1)\n",
    "cv2.imshow(\"Original\" , img)\n",
    "\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "# using a gaussian blur\n",
    "blur = cv2.GaussianBlur(gray , (3,3) , 0)\n",
    "# adap\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C , cv2.THRESH_BINARY_INV , 205,1)\n",
    "cv2.imshow(\"Threshold\", thresh)\n",
    "\n",
    "# drawing contours\n",
    "contours , hierarchy = cv2.findContours(thresh , cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
    "print (len(contours))\n",
    "\n",
    "\n",
    "# We only want to draw largest contours\n",
    "\n",
    "filtered = []\n",
    "for c in contours:\n",
    "    if cv2.contourArea(c) < 1000:continue\n",
    "    filtered.append(c)\n",
    "\n",
    "    \n",
    "\n",
    "print (len(filtered)) # contours > 1000 pixels squared\n",
    "\n",
    "objects = np.zeros([img.shape[0] , img.shape[1] , 3] , 'uint8')\n",
    "\n",
    "\n",
    "for c in filtered:\n",
    "    col = (random.randint(0,255) , random.randint(0,255) , random.randint(0,255))\n",
    "    cv2.drawContours(objects , c , -1 , color , -1)\n",
    "    area = cv2.contourArea(c)\n",
    "    perimeter = cv2.arcLength(c , True)\n",
    "    print (area , perimeter)\n",
    "cv2.imshow(\"Contours\" , objects)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
